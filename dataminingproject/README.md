# Compression de LLM pour l'Informatique de Bord - Guide Complet du Projet

Un projet complet qui compresse les Grands Mod√®les de Langage (LLM) pour les rendre adapt√©s aux appareils de bord, avec une interface chatbot interactive pour comparer les performances des mod√®les.

---

## üìñ Ce Que Ce Projet Fait

Ce projet d√©montre comment :
1. **Compresser de grands mod√®les IA** (BERT) en versions plus petites et plus rapides (DistilBERT)
2. **R√©duire la taille des mod√®les** jusqu'√† 85% tout en maintenant une bonne pr√©cision
3. **Comparer les mod√®les** c√¥te √† c√¥te en utilisant une interface web
4. **Pr√©parer les mod√®les** pour le d√©ploiement sur des appareils √† ressources limit√©es (t√©l√©phones, appareils IoT, etc.)

---

## üéØ Vue d'Ensemble du Projet

### Partie 1 : Pipeline de Compression de Mod√®le (Notebook Jupyter)
Le notebook (`Extreme_LLM_Compression_for_Edge_Computing.ipynb`) contient un pipeline complet qui :

- **Entra√Æne** un grand mod√®le BERT (109M param√®tres) sur l'analyse de sentiment
- **Le compresse** en utilisant plusieurs techniques :
  - Distillation de connaissances (transfert de connaissances vers un mod√®le plus petit)
  - √âlagage (suppression de poids inutiles)
  - Quantification (r√©duction de pr√©cision de 32 bits √† 8 bits)
  - Conversion ONNX (optimisation pour le d√©ploiement)
- **Mesure** les performances √† chaque √©tape

### Partie 2 : Interface Chatbot Interactive (Application Flask)
Une application web qui vous permet de :
- Saisir du texte et voir les pr√©dictions de sentiment
- Comparer BERT vs mod√®le compress√© c√¥te √† c√¥te
- Voir les diff√©rences de vitesse et de pr√©cision en temps r√©el

---

## üìÅ Structure du Projet

```
dataminingproject/
‚îÇ
‚îú‚îÄ‚îÄ Extreme_LLM_Compression_for_Edge_Computing.ipynb  # Pipeline de compression principal
‚îÇ
‚îú‚îÄ‚îÄ app.py                    # Application web Flask
‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html           # Interface web
‚îÇ
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ style.css        # Styles
‚îÇ   ‚îî‚îÄ‚îÄ js/
‚îÇ       ‚îî‚îÄ‚îÄ script.js        # Fonctionnalit√©s interactives
‚îÇ
‚îî‚îÄ‚îÄ models/                   # Mod√®les sauvegard√©s (cr√©√©s apr√®s l'entra√Ænement)
    ‚îú‚îÄ‚îÄ teacher/             # Fichiers du mod√®le BERT
    ‚îî‚îÄ‚îÄ student/             # Fichiers du mod√®le compress√©
```

---

## üöÄ Guide de D√©marrage Rapide

### √âtape 1 : Comprendre Ce Dont Vous Avez Besoin

**Requis :**
- Python 3.8 ou sup√©rieur
- Jupyter Notebook (pour ex√©cuter le pipeline de compression)
- Un ordinateur avec GPU (recommand√©) ou CPU
- Connexion Internet (pour t√©l√©charger les mod√®les et les jeux de donn√©es)

### √âtape 2 : Configurer l'Environnement

1. **Ouvrir le Terminal** et naviguer vers le dossier du projet :
   ```bash
   cd dataminingproject
   ```

2. **Cr√©er un environnement virtuel** (optionnel mais recommand√©) :
   ```bash
   python -m venv venv
   source venv/bin/activate  # Sur Windows: venv\Scripts\activate
   ```

3. **Installer les packages requis** :
   ```bash
   pip install -r requirements.txt
   ```

   Si vous n'avez pas `requirements.txt`, installez ces packages :
   ```bash
   pip install jupyter transformers datasets torch flask
   ```

### √âtape 3 : Ex√©cuter le Pipeline de Compression (Optionnel)

**Cette √©tape entra√Æne et compresse les mod√®les. Vous pouvez l'ignorer si vous voulez simplement utiliser des mod√®les pr√©-entra√Æn√©s.**

1. **Ouvrir Jupyter Notebook** :
   ```bash
   jupyter notebook
   ```

2. **Ouvrir** `Extreme_LLM_Compression_for_Edge_Computing.ipynb`

3. **Ex√©cuter toutes les cellules** s√©quentiellement (cela prend du temps - 30-60 minutes) :
   - Le notebook va :
     - T√©l√©charger le jeu de donn√©es SST-2 de sentiment
     - Entra√Æner BERT sur l'analyse de sentiment
     - Le compresser en DistilBERT
     - Appliquer l'√©lagage et la quantification
     - Sauvegarder les mod√®les dans le dossier `models/`

4. **Sauvegarder les mod√®les** (ils seront sauvegard√©s automatiquement dans le notebook)

### √âtape 4 : Ex√©cuter l'Interface Chatbot

1. **Assurez-vous d'√™tre dans le r√©pertoire du projet**

2. **D√©marrer le serveur Flask** :
   ```bash
   python app.py
   ```

3. **Ouvrir votre navigateur web** et aller √† :
   ```
   http://localhost:5001
   ```

4. **Commencer √† comparer les mod√®les !**
   - Tapez n'importe quelle phrase dans la zone de saisie
   - Cliquez sur "Analyser"
   - Voyez les pr√©dictions des deux mod√®les c√¥te √† c√¥te

---

## üìù Instructions D√©taill√©es √âtape par √âtape

### Comprendre le Pipeline de Compression

Le notebook suit ces √©tapes :

#### √âtape 1 : Pr√©paration des Donn√©es
- Utilise le jeu de donn√©es **SST-2** (Stanford Sentiment Treebank)
- Contient des critiques de films √©tiquet√©es comme positives ou n√©gatives
- Divise les donn√©es en : entra√Ænement (5 000 √©chantillons), validation (500), test (1 000)

#### √âtape 2 : Entra√Ænement du Mod√®le Enseignant
- **Mod√®le** : BERT-base-uncased (109 millions de param√®tres)
- **T√¢che** : Classification binaire de sentiment
- **Entra√Ænement** : 3 √©poques
- **R√©sultat** : Mod√®le qui peut classer le texte comme positif ou n√©gatif

#### √âtape 3 : Distillation de Connaissances
- **Mod√®le √âtudiant** : DistilBERT (67 millions de param√®tres - 39% plus petit)
- **Processus** : Le mod√®le plus petit apprend des pr√©dictions du mod√®le plus grand
- **R√©sultat** : Mod√®le compress√© avec une pr√©cision similaire (88,8% vs 89,4%)

#### √âtape 4 : √âlagage
- **M√©thode** : Supprime 30% des poids les moins importants
- **R√©sultat** : Maintient la pr√©cision tout en r√©duisant la complexit√© computationnelle

#### √âtape 5 : Quantification
- **Processus** : Convertit les poids de 32 bits √† 8 bits de pr√©cision
- **R√©sultat** : 68% de r√©duction de taille (255MB ‚Üí 132MB)

#### √âtape 6 : Conversion ONNX
- **Format** : Convertit en ONNX (Open Neural Network Exchange)
- **Objectif** : Optimis√© pour le d√©ploiement sur divers appareils

#### √âtape 7 : Benchmarking
- Mesure la pr√©cision, la latence et la taille du mod√®le √† chaque √©tape
- Cr√©e des graphiques de comparaison et des statistiques

### Comprendre l'Interface Chatbot

L'application Flask fournit :

1. **Interface Interactive**
   - Design web moderne et √©pur√©
   - Saisie de texte facile √† utiliser
   - Pr√©dictions en temps r√©el

2. **Comparaison C√¥te √† C√¥te**
   - Montre les pr√©dictions des deux mod√®les
   - Affiche les scores de confiance
   - Montre le temps d'inf√©rence (la vitesse de chaque mod√®le)

3. **Tableau de Bord de Statistiques**
   - Suit combien de fois les mod√®les sont d'accord
   - Montre le facteur d'acc√©l√©ration (√† quel point le mod√®le compress√© est plus rapide)
   - Affiche le nombre total de requ√™tes analys√©es

---

## üéì Ce Que Fait Chaque Composant

### Notebook Jupyter (`Extreme_LLM_Compression_for_Edge_Computing.ipynb`)

**Objectif** : Entra√Æner et compresser les mod√®les

**Ce qu'il fait** :
- T√©l√©charge et pr√©pare les donn√©es
- Entra√Æne un grand mod√®le BERT
- Le compresse en utilisant plusieurs techniques
- Mesure les m√©triques de performance
- Sauvegarde les mod√®les compress√©s

**Temps requis** : 30-60 minutes (selon le mat√©riel)

**Sortie** : Mod√®les entra√Æn√©s sauvegard√©s dans le dossier `models/`

### Application Flask (`app.py`)

**Objectif** : Comparer les mod√®les de mani√®re interactive

**Ce qu'elle fait** :
- Charge les mod√®les BERT et compress√©
- Fournit une interface web pour les tests
- Montre des comparaisons en temps r√©el
- Calcule les m√©triques de performance

**Temps de d√©marrage** : 1-2 minutes (pour charger les mod√®les)

**Sortie** : Interface web √† http://localhost:5001

---

## üìä R√©sultats Attendus

Apr√®s avoir ex√©cut√© le pipeline de compression, vous devriez voir :

| Mod√®le | Taille | Pr√©cision | Vitesse | Param√®tres |
|--------|--------|-----------|---------|------------|
| **BERT-base** (Enseignant) | 418 MB | 89,4% | 23,5 ms | 109M |
| **DistilBERT** (Compress√©) | 255 MB | 88,8% | 8,2 ms | 67M |
| **Acc√©l√©ration** | **38% plus petit** | **-0,6%** | **2,9x plus rapide** | **39% de moins** |

**R√©alisations Cl√©s** :
- ‚úÖ 38% de r√©duction de taille
- ‚úÖ 2,9x inf√©rence plus rapide
- ‚úÖ Seulement 0,6% de perte de pr√©cision
- ‚úÖ 84% de r√©duction de taille avec quantification (132 MB)

---

## üí° Comment Utiliser le Chatbot

1. **D√©marrer l'application** :
   ```bash
   python app.py
   ```

2. **Attendre que les mod√®les se chargent** (vous verrez des messages dans le terminal)

3. **Ouvrir le navigateur** : Aller √† `http://localhost:5001`

4. **Essayer des exemples** :
   - **Positif** : "Ce film est absolument fantastique !"
   - **N√©gatif** : "J'ai d√©test√© ce film, il √©tait terrible."
   - **Neutre** : "L'intrigue √©tait correcte, rien de sp√©cial."

5. **Observer les diff√©rences** :
   - V√©rifier si les deux mod√®les sont d'accord
   - Comparer les scores de confiance
   - Voir la diff√©rence de vitesse (latence)
   - Regarder les statistiques se mettre √† jour

---

## üîß D√©pannage

### Probl√®me : "Le port 5000 est d√©j√† utilis√©"
**Solution** : L'application utilise le port 5001 par d√©faut. Si vous avez besoin d'un autre port :
```bash
FLASK_PORT=8080 python app.py
```

### Probl√®me : Les mod√®les prennent trop de temps √† charger
**Solution** : C'est normal lors de la premi√®re ex√©cution. Les mod√®les t√©l√©chargent depuis HuggingFace (~700MB). Les ex√©cutions suivantes seront plus rapides.

### Probl√®me : Erreur "Mod√®le non trouv√©"
**Solution** : 
- Si vous n'avez pas entra√Æn√© de mod√®les, l'application utilisera des mod√®les pr√©-entra√Æn√©s depuis HuggingFace (c'est bien !)
- Pour utiliser vos mod√®les entra√Æn√©s, copiez-les dans `models/teacher/` et `models/student/`

### Probl√®me : Erreurs de m√©moire insuffisante
**Solution** : 
- Fermez les autres applications
- L'application fonctionne sur CPU si vous n'avez pas de GPU
- R√©duisez la taille des lots dans le notebook si vous entra√Ænez

### Probl√®me : Le notebook Jupyter ne d√©marre pas
**Solution** :
```bash
pip install jupyter
jupyter notebook
```

---

## üéØ Cas d'Usage

Ce projet est utile pour :

1. **Apprendre** : Comprendre comment fonctionne la compression de mod√®les
2. **Recherche** : Comparer les techniques de compression
3. **D√©ploiement** : Pr√©parer les mod√®les pour les appareils de bord
4. **√âducation** : Enseigner les concepts de compression ML
5. **D√©veloppement** : Construire des applications IA l√©g√®res

---

## üìö Concepts Cl√©s Expliqu√©s Simplement

### Distillation de Connaissances
**Quoi** : Un mod√®le "√©tudiant" plus petit apprend d'un mod√®le "enseignant" plus grand
**Pourquoi** : Obtenir des performances similaires avec moins de ressources
**Analogies** : Comme un √©tudiant apprenant d'un enseignant exp√©riment√©

### √âlagage
**Quoi** : Supprimer les parties inutiles du mod√®le
**Pourquoi** : R√©duire la taille sans perdre beaucoup de pr√©cision
**Analogies** : Comme tailler un arbre - enlever des branches mais le garder en bonne sant√©

### Quantification
**Quoi** : Utiliser moins de bits pour stocker les nombres (32 bits ‚Üí 8 bits)
**Pourquoi** : R√©duire drastiquement la taille du mod√®le
**Analogies** : Comme compresser une photo - fichier plus petit, qualit√© l√©g√®rement inf√©rieure

### ONNX
**Quoi** : Format standard pour les mod√®les IA
**Pourquoi** : Fonctionne sur de nombreux appareils diff√©rents
**Analogies** : Comme un format de fichier universel (comme PDF)

---

## üîÑ R√©sum√© du Flux de Travail

```
1. Ex√©cuter le Notebook
   ‚Üì
2. Entra√Æner le Mod√®le BERT (Enseignant)
   ‚Üì
3. Compresser en DistilBERT (√âtudiant)
   ‚Üì
4. Appliquer l'√âlagage et la Quantification
   ‚Üì
5. Sauvegarder les Mod√®les
   ‚Üì
6. Ex√©cuter l'Application Flask
   ‚Üì
7. Comparer les Mod√®les dans le Navigateur
   ‚Üì
8. Analyser les R√©sultats
```

---

## üì¶ Pr√©requis

### Pour Ex√©cuter le Notebook :
- Python 3.8+
- Jupyter Notebook
- GPU recommand√© (CPU fonctionne mais plus lent)
- 10GB+ d'espace disque (pour les mod√®les et les donn√©es)

### Pour Ex√©cuter l'Application Flask :
- Python 3.8+
- Flask
- Biblioth√®que Transformers
- 2GB+ de RAM
- Navigateur web

### Packages Python :
```
torch
transformers
datasets
flask
numpy
pandas
matplotlib
seaborn
jupyter
```

---

## üéì Objectifs d'Apprentissage

Apr√®s avoir compl√©t√© ce projet, vous comprendrez :

1. ‚úÖ Comment entra√Æner des mod√®les de transformateurs pour des t√¢ches NLP
2. ‚úÖ La technique de distillation de connaissances
3. ‚úÖ Les m√©thodes d'√©lagage de mod√®les
4. ‚úÖ Les techniques de quantification
5. ‚úÖ Les consid√©rations de d√©ploiement de mod√®les
6. ‚úÖ Les compromis de performance dans la compression de mod√®les
7. ‚úÖ La construction d'applications ML interactives

---

## üìñ Ressources Additionnelles

- **Article BERT** : [arXiv:1810.04805](https://arxiv.org/abs/1810.04805)
- **Article DistilBERT** : [arXiv:1910.01108](https://arxiv.org/abs/1910.01108)
- **HuggingFace** : https://huggingface.co/
- **ONNX** : https://onnx.ai/

---

## ü§ù Obtenir de l'Aide

Si vous rencontrez des probl√®mes :

1. V√©rifiez attentivement les messages d'erreur
2. Consultez la section de d√©pannage ci-dessus
3. Assurez-vous que toutes les d√©pendances sont install√©es
4. V√©rifiez que la version Python est 3.8 ou sup√©rieure
5. Assurez-vous d'avoir assez d'espace disque

---

## ‚úÖ Liste de V√©rification Rapide

Avant de commencer :
- [ ] Python 3.8+ install√©
- [ ] Dossier du projet t√©l√©charg√©
- [ ] Acc√®s Terminal/ligne de commande
- [ ] Connexion Internet (pour les t√©l√©chargements)

Pour ex√©cuter le notebook :
- [ ] Jupyter install√©
- [ ] Tous les packages Python install√©s
- [ ] GPU disponible (optionnel mais recommand√©)

Pour ex√©cuter l'application Flask :
- [ ] Flask install√©
- [ ] Mod√®les disponibles (ou utiliser le repli HuggingFace)
- [ ] Port 5001 disponible
- [ ] Navigateur web install√©

---

## üéâ Indicateurs de Succ√®s

Vous avez r√©ussi √† compl√©ter le projet quand :

1. ‚úÖ Le notebook s'ex√©cute sans erreurs
2. ‚úÖ Les mod√®les sont entra√Æn√©s et sauvegard√©s
3. ‚úÖ L'application Flask d√©marre avec succ√®s
4. ‚úÖ L'interface web se charge dans le navigateur
5. ‚úÖ Vous pouvez obtenir des pr√©dictions des deux mod√®les
6. ‚úÖ Vous pouvez voir les diff√©rences de performance

---

## üìù R√©sum√©

Ce projet vous enseigne comment :
- Compresser de grands mod√®les IA pour le d√©ploiement en bord
- Comparer les performances des mod√®les de mani√®re interactive
- Comprendre les compromis entre taille, vitesse et pr√©cision
- Construire des applications ML pratiques

**Commencez par le notebook pour entra√Æner les mod√®les, puis utilisez l'application Flask pour les comparer !**

---

**Bon Apprentissage ! üöÄ**
